\section{K is for Kernel Width \hpoints{42}}

\paragraph{Description.} A hospital wants to know whether or not you can help them to detect
breast cancer in their patients quickly and reliably and have sent you
this data that they have collected from patients with confirmed to
have/not have breast cancer: \url{ftp://ftp.ics.uci.edu/pub/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names}. We
have removed the records with missing values for you. {\bf We have
  included two versions of the dataset: the original data, and an
  additional version with noise added.} Obviously, there are
patients lives at risk here, so they want you to make sure that your
model can accurately detect breast cancer on new patients
(they already know the diagnosis for the ones in the data set they've given you).

So how can we build the best model possible and be confident of how accurate it will be on future patients, given the limited data that they have provided us? In general, the answer is to set aside a randomly selected set of patients that we do NOT use for training. Often we do not have enough such patients, and so we use N-fold cross validation on training set to estimate the ``true test error". Your task here is to observe the relationship between N-fold cross validation error and true test error.

\paragraph{Your task.}
The goal here is to 1) implement two simple classifiers K-NN and kernel regression respectively which is a good practice for you to be familar with coding with matlab and 2) compare the N-fold classification estimate and the true test error of the dataset; 
you will then use your estimates of test error to determine the optimal kernel width $\sigma$ and \# of neighbors $K$ to optimize the performance of kernel regression and K-nearest neighbors for this task. 
You will need to do the following:

\begin{itemize}
\item Implement four matlab functions,  {\tt k\_nearest\_neighbours.m},  {\tt kernel\_regression.m}, 
{\tt knn\_xval\_error.m} \\
and {\tt kernreg\_xval\_error.m}. 
Have a careful look at the matlab files for exact specifications of what these functions should do.

\end{itemize}
Now that you've finished your implementation, compare the N-fold
cross-validation estimate and true test set error on the standard and
noisy datasets by answering the following questions. You will be given a dataset consisting of 600 data points, along with their labels. You will first have to randomly partition the dataset into a training set, and a testing set. We suggest using 450 data points for training and the remaining 150 for testing. For all experiments please use the training dataset to train your classifier and to perform cross validation, and use the test set for testing its performance.

\begin{itemize}
\item For both the original data and the noisy, compute both the
  $N$-fold error on the training set, for $N = \{3, 5, 9, 15\}$, and the test error for K-NN, and Kernel Regression with $K = 1$ and $\sigma = 1$ respectively.  What trend do you observe? Please plot the cross-validation error and test error in the same figure.
 {\bf Note that any two random partitions of the data will yield somewhat different curves. Therefore, you must repeat all of the above steps 100 times, using different random partitions into training and testing.}

 \paragraph{Your answer:}
 ~\\
 
 {\tt  [Figure on original data with KNN]}
 \\    
 
 {\tt [Figure on noisy data with KNN]}
 \\

  {\tt  [Figure on original data with Kernel Regression]}
 \\    
 
  {\tt  [Figure on noisy data with Kernel Regression]}
 \\    

\item For both the original data and the noisy, compute both the
  10-fold cross validation error on the training set and the test error for K-NN with
  $K \in \{1, 3, 4, 6, 9, 14, 22, 35\}$ and for Kernel Regression with $\sigma \in \{1, 3, 5, 7, 9, 11\}$.  Generate {\bf
    four plots}: each plot will show $K$ (for K-NN) or $\sigma$ (for
  kernel regression) on the X axis, and error on the Y axis. The plot
  will have two lines, one for 10-fold error, and the
  other for test set error; you will have one plot for each
  method/dataset combination (e.g., K-NN on standard, K-NN on noisy,
  etc.). Based on these charts, can you pick the best $\sigma$ and $K$
  to minimize test set error using cross validation (on average) for both original and noisy data? Which are the best values? 
  
  \paragraph{Your answer:}
 ~\\
 
 {\tt  [Figure on original data with KNN]}
 \\    
 
 {\tt [Figure on noisy data with KNN]}
 \\

  {\tt  [Figure on original data with Kernel Regression]}
 \\    
 
  {\tt  [Figure on noisy data with Kernel Regression]}
 \\    
 
 The best $\sigma$ is  \ldots, the best $K$ is \ldots  .

  
 \emph{\textsc{N-fold error and test error clarification:} N-fold error is the error over the training set, and test error is the error when you test your trained classifier (trained over the entire training set) on test set. N-fold cross validation is used for choosing the best parameters. }

\end{itemize}
